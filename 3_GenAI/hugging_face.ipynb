{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYRe8u5CsLyLNo0UZiL/l7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pearl-yu/mist5400fall2025/blob/main/3_GenAI/hugging_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MIST 5400 Lab: Using models from huggingFace\n",
        "\n",
        "Adapted from huggingface example notebooks.\n",
        "\n",
        "By Pearl Yu"
      ],
      "metadata": {
        "id": "vxcPSPOUFgnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quickstart\n",
        "\n",
        "Transformers is designed to be fast and easy to use so that everyone can start learning or building with transformer models.\n",
        "\n",
        "This quickstart introduces you to Transformers' key features and shows you how to:\n",
        "\n",
        "- load a pre-trained model and run inference with [Pipeline](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.Pipeline)\n",
        "- fine-tune a model with [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)"
      ],
      "metadata": {
        "id": "86hnsYtsFoSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First, install the transformers libraries"
      ],
      "metadata": {
        "id": "wdIZapmlFxaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers installation\n",
        "! pip install transformers datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "5GiKsMvrFjiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pretrained Models\n",
        "\n",
        "The [Pipeline](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.Pipeline) class is the most convenient way to inference with a pretrained model. It supports many tasks such as text generation, image segmentation, automatic speech recognition, document question answering, and more.\n",
        "\n",
        "> [!TIP]\n",
        "> Refer to the [Pipeline](https://huggingface.co/docs/transformers/main/en/./main_classes/pipelines) API reference for a complete list of available tasks.\n",
        "\n",
        "Create a [Pipeline](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.Pipeline) object and select a task. By default, [Pipeline](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.Pipeline) downloads and caches a default pretrained model for a given task. Pass the model name to the `model` parameter to choose a specific model.\n",
        "\n",
        "<hfoptions id=\"pipeline-tasks\">\n",
        "<hfoption id=\"text generation\">\n",
        "\n",
        "Use `Accelerator` to automatically detect an available accelerator for inference."
      ],
      "metadata": {
        "id": "0x727mQAF3v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation"
      ],
      "metadata": {
        "id": "Q4ePRuzRu6-x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQiHHwqohVeV"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from accelerate import Accelerator\n",
        "\n",
        "device = Accelerator().device\n",
        "\n",
        "pipeline_text = pipeline(\"text-generation\", model=\"distilgpt2\", device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaeKib_YhVeV"
      },
      "source": [
        "Prompt [Pipeline](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.Pipeline) with some initial text to generate more text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOQnbGcDhVeV"
      },
      "outputs": [],
      "source": [
        "pipeline_text(\"The secret to baking a good cake is \", truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ze26bSeGF4VI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}